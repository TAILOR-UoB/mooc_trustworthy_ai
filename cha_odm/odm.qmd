---
title: Optimal Decision Making
author: 
  - name:
      given: Miquel
      family: Perello Nieto
    orcid: 0000-0001-8925-424X
    email: miquel.perellonieto@bristol.ac.uk
    affiliations:
      - name: University of Bristol
        city: Bristol
        country: United Kingdom
        postal-code: BS8 1QU
    attributes:
        equal-contributor: False
includes:
  in_header: "definitions.tex"
---

{{< include commands.tex >}}

# Cost-sensitive Classification

## Binary examples

|          | Predicted $C_1$               | Predicted $C_2$ |
|-|-|-|
|True $C_1$ | $\color{darkgreen}{0}$    | $\color{darkred}{1}$ |
|True $C_2$ | $\color{darkred}{1}$      | $\color{darkgreen}{0}$ |

\begin{equation}
  l(\vec{x},i) = \sum_{j = 1}^K P(C_j|\vec{x}) c_{i|j}.
\end{equation}

- Predicting **Class 1** will have an expected cost of $0.4 \times 0 +
    0.6 \times 1 = \color{darkred}{0.6}$
- Predicting **Class 2** will have an expected cost of $0.4 \times 1
    + 0.6 \times 0 = \mathbf{\color{darkred}{0.4}}$.

```{python}
#| code-fold: true
#| code-summary: "Show the code"
import matplotlib.pyplot as plt

C = [[0, 1], [1, 0]]
threshold = (C[0][1] - C[1][1])/(C[0][1] - C[1][1] + C[1][0] - C[0][0])
cost_t = threshold*C[0][0] + (1-threshold)*C[0][1]
plt.grid(True)
plt.plot([0, 1], [C[0][1], C[0][0]], '--', label="Predict $C_1$")
plt.plot([0, 1], [C[1][1], C[1][0]], '--', label="Predict $C_2$")
plt.plot([threshold, 1], [cost_t, C[0][0]], lw=5, color='tab:blue', label="Optimal $C_1$")
plt.plot([0, threshold], [C[1][1], cost_t], lw=5, color='tab:orange', label="Optimal $C_2$")
plt.xlabel('$P(C_1|x)$')
plt.ylabel('Expected cost')
plt.legend()
plt.annotate("Cost = 0.4", (0.6, 0.38), xytext=(0.5, 0.2),
             arrowprops=dict(arrowstyle='->', facecolor='black'))
plt.scatter(0.6, 0.4, s=100, facecolors='none', edgecolors='tab:red', zorder=10)
plt.show()
```

## Cost Matrix "reasonableness" condition

It is reasonable to expect cost matrices where:

1. For a given class $j$ the correct prediction has always a lower cost than an
incorrect prediction $c_{j|j} < c_{i|j}$ with $i \neq j$.
2. And one class does not consistently have lower costs than other classes
$c_{i|j} \leq c_{k|j}$ for all $j$ (class domination).

### Cost Matrix Class Domination

The following is an example of class domination.

|               | Predicted $C_1$       | Predicted $C_2$      |
|---------------|---------------------------|--------------------------|
|True $C_1$ | $\color{darkgreen}{0}$    | $\color{darkred}{1}$   |
|True $C_2$ | $\color{darkred}{0.4}$      | $\color{darkgreen}{0.5}$ |

```{python}
#| code-fold: true
#| code-summary: "Show the code"
import matplotlib.pyplot as plt

plt.grid(True)
plt.plot([0, 1], [0.4, 0], '--', color='tab:blue', label="Predict $C_1$")
plt.plot([0, 1], [0.5, 1], '--', color='tab:orange', label="Predict $C_2$")
plt.plot([0, 1], [0.4, 0], lw=5, color='tab:blue', label="Optimal $C_1$")
plt.xlabel('$P(C_1|x)$')
plt.ylabel('Expected cost')
plt.legend()
plt.show()
```

## Multiclass setting

|              | Predicted $C_1$              | Predicted $C_2$              | $\cdots$ | Predicted $C_K$                |
|--------------|------------------------------|------------------------------|----------|--------------------------------|
| True $C_1$   | $\color{darkgreen}{c_{1|1}}$ | $\color{darkred}{c_{1|2}}$   | $\cdots$ | $\color{darkred}{c_{1|K}}$     |
| True $C_2$   | $\color{darkred}{c_{2|1}}$   | $\color{darkgreen}{c_{2|2}}$ | $\cdots$ | $\color{darkred}{c_{2|K}}$     |
| $\vdots$     | $\vdots$ 			   	 	  | $\vdots$                     | $\ddots$ | $\vdots$                       |
| True $C_K$   | $\color{darkred}{c_{K|1}}$   | $\color{darkred}{c_{K|2}}$   | $\cdots$ | $\color{darkgreen}{c_{K|K}}$   |


## Optimal Decision

\begin{equation}
  \hat{y}(\vec{x}) = \argmin_{i=\{1, \dots, K\}} L(\vec{x},i)
                   = \argmin_{i=\{1, \dots, K\}} \sum_{j=1}^K P(C_j|\vec{x}) c_{i|j}.
\end{equation}

In the binary classification setting we can also derive the optimal threshold to
predict the second class $C_2$

\begin{equation}
  t_2^* = \frac{{\color{darkred}c_{1|2}} - {\color{darkgreen}c_{2|2}}}
               {{\color{darkred}c_{1|2}} - {\color{darkgreen}c_{2|2}} +
                {\color{darkred}c_{2|1}} - {\color{darkgreen}c_{1|1}}}.
\end{equation}

Which for the previous cost matrix corresponds to

\begin{equation}
  t_2^* = \frac{1 - 0}{1 + 1 - 0 - 0} = 0.5
\end{equation}


|               | Predicted $C_1$       | Predicted $C_2$      |
|---------------|---------------------------|--------------------------|
|True $C_1$ | $\color{darkgreen}{-5}$    | $\color{darkred}{10}$   |
|True $C_2$ | $\color{darkred}{1}$      | $\color{darkgreen}{-1}$ |

\begin{itemize}
  \item Predicting **Class 1** will have an expected gain of $5 \times 0.4 - 1 \times
    0.6 = \mathbf{\color{darkgreen}{1.4}}$
  \item Predicting **Class 2** will have an expected gain of $-10 \times 0.4 + 1 \times
    0.6 = \color{darkred}{-3.4}$
\end{itemize}



```{python}
#| code-fold: true
#| code-summary: "Show the code"
import matplotlib.pyplot as plt

C = [[-5, 1], [10, -1]]
threshold = (C[0][1] - C[1][1])/(C[0][1] - C[1][1] + C[1][0] - C[0][0])
cost_t = threshold*C[0][0] + (1-threshold)*C[0][1]
plt.grid(True)
plt.plot([0, 1], [C[0][1], C[0][0]], '--', label="Predict $C_1$")
plt.plot([0, 1], [C[1][1], C[1][0]], '--', label="Predict $C_2$")
plt.plot([threshold, 1], [cost_t, C[0][0]], lw=5, color='tab:blue', label="Optimal $C_1$")
plt.plot([0, threshold], [C[1][1], cost_t], lw=5, color='tab:orange', label="Optimal $C_2$")
plt.xlabel('$P(C_1|x)$')
plt.ylabel('Expected cost')
plt.legend()
plt.show()
```

|              | Predicted $C_1$ | Predicted $C_2$ | Predicted $C_3$   |
|--------------|-----------------|-----------------|-------------------|
| True $C_1$   | -10 |  20 |  30   |
| True $C_2$   |  40 | -50 |  60   |
| True $C_3$   |  70 |  80 | -90   |


- Predicting Class 1 will have a gain of 
$10 \times 0.5 - 40 \times 0.1 -70 \times 0.4 = \color{darkred}{-27}$
- Predicting Class 2 will have a gain of 
$-20 \times 0.5 + 50 \times 0.1 -80 \times 0.4 = \color{darkred}{-37}$
- Predicting Class 3 will have a gain of 
$-30 \times 0.5 - 60 \times 0.1  90 \times 0.4 = \mathbf{\color{darkgreen}{15}}$

```{python}
#| code-fold: true
#| code-summary: "Show the code"
import matplotlib.pyplot as plt
from pycalib.visualisations.barycentric import draw_func_contours

C = [[-10, 40, 70], [20, -50, 80], [30, 60, -90]]

cmaps = ['Blues_r', 'Oranges_r', 'Greens_r']
labels = [f"$P(C_{i+1}|x) = 1$" for i in range(len(C))]

fig = plt.figure(figsize=(10, 4))
for i in range(len(C)):
    ax = fig.add_subplot(1, len(C), i+1)

    def cost_func(prob):
        return sum(prob*C[i])

    ax.set_title(f"Expected cost of predicting $C_{i+1}$\n")
    draw_func_contours(cost_func, labels=labels, nlevels=20, subdiv=3,
                       cmap=cmaps[i], fig=fig, ax=ax)
```


```{python}
#| code-fold: true
#| code-summary: "Show the code"
import matplotlib
import numpy as np
import matplotlib.pyplot as plt
from pycalib.visualisations.barycentric import draw_func_contours

C = [[-10, 40, 70], [20, -50, 80], [30, 60, -90]]

cmaps = ['Blues_r', 'Oranges_r', 'Greens_r']
labels = [f"$P(C_{i+1}|x) = 1$" for i in range(len(C))]

fig = plt.figure(figsize=(10, 4))
for i in range(len(C)):
    ax = fig.add_subplot(1, len(C), i+1)

    def cost_func(prob):
        expected_costs = np.inner(prob, C)
        min_p_id = np.argmin(expected_costs)
        if min_p_id == i:
            return expected_costs[i]
        return np.nan

    ax.set_title(f"Expected cost of predicting $C_{i+1}$\n")
    draw_func_contours(cost_func, labels=labels, nlevels=10, subdiv=3,
                       cmap=cmaps[i],    fig=fig, ax=ax)

plt.show()
```

```{python}
#| code-fold: true
#| code-summary: "Show the code"
import matplotlib
import numpy as np
import matplotlib.pyplot as plt
from pycalib.visualisations.barycentric import draw_func_contours

C = [[-10, 40, 70], [20, -50, 80], [30, 60, -90]]

cmaps = ['Blues_r', 'Oranges_r', 'Greens_r']
labels = [f"$P(C_{i+1}|x) = 1$" for i in range(len(C))]

fig = plt.figure(figsize=(5, 5))
ax = fig.add_subplot()
ax.set_title(f"Expected cost of predicting the optimal class\n")
for i in range(len(C)):
    def cost_func(prob):
        expected_costs = np.inner(prob, C)
        min_p_id = np.argmin(expected_costs)
        if min_p_id == i:
            return expected_costs[i]
        return np.nan

    draw_func_contours(cost_func, labels=labels, nlevels=10, subdiv=5,
                       cmap=cmaps[i],    fig=fig, ax=ax)


plt.show()
```


|              | Predicted $C_1$ | Predicted $C_2$ | Abstain |
|--------------|-----------------|-----------------|---------|
| True $C_1$   | 0 | 10 | 2 |
| True $C_2$   | 9 | -3 | 2 |



- Predicting **Class 1** has an expected gain of
$0 \times 0.3 - 9 \times 0.7 = \color{darkred}{-6.3}$
- Predicting **Class 2** has an expected gain of
$-10 \times 0.3 + 3 \times 0.7 = \color{darkred}{-0.9}$
- **Abstaining** has an expected gain of
$-2 \times 0.3 + 1 \times 0.7 = \mathbf{\color{darkgreen}{0.1}}$


```{python}
#| code-fold: true
#| code-summary: "Show the code"
import numpy as np
import matplotlib.pyplot as plt

C = [[0, 9], [10, -3], [2, 2]]
p = np.linspace(0, 1, 100)
p = np.vstack([1 - p, p]).T
opt_cost = [min(np.inner(C, p[i])) for i in range(p.shape[0])]
plt.plot(p[:,0], opt_cost, lw=3, label='Optimal')

plt.grid(True)
plt.plot([0, 1], [C[0][1], C[0][0]], '--', label="Predict $C_1$")
plt.plot([0, 1], [C[1][1], C[1][0]], '--', label="Predict $C_2$")
plt.plot([0, 1], [C[2][1], C[2][0]], '--', c='tab:red', label="Abstain")
plt.xlabel('$P(C_1|x)$')
plt.ylabel('Expected cost')
plt.legend()
plt.show()
```

|              | Predicted $C_1$ | Predicted $C_2$ | Abstain |
|--------------|-----------------|-----------------|---------|
| True $C_1$   | 0 | 10 |  2 |
| True $C_2$   | 9 | -3 | -1 |


```{python}
#| code-fold: true
#| code-summary: "Show the code"
import numpy as np
import matplotlib.pyplot as plt

C = np.array([[0, 9], [10, -3], [2, -1]])
p = np.linspace(0, 1, 100)
p = np.vstack([1 - p, p]).T
opt_cost = [min(np.inner(C, p[i])) for i in range(p.shape[0])]
plt.plot(p[:,0], opt_cost, lw=3, label='Optimal')

plt.grid(True)
plt.plot([0, 1], [C[0][1], C[0][0]], '--', label="Predict $C_1$")
plt.plot([0, 1], [C[1][1], C[1][0]], '--', label="Predict $C_2$")
plt.plot([0, 1], [C[2][1], C[2][0]], '--', c='tab:red', label="Abstain")
plt.xlabel('$P(C_1|x)$')
plt.ylabel('Expected cost')
plt.legend()
plt.show()
```
