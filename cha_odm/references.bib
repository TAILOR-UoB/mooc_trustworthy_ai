@InProceedings{   elkan2001,
  author = {Elkan, Charles},
  booktitle = {17th International Conference on Artificial Intelligence
    (IJCAI'01)},
  editor = {Kaufmann, Morgan},
  number = {May 2001},
  pages  = {973----978},
  title  = {{The Foundations of Cost-Sensitive Learning The
    Foundations of Cost-Sensitive Learning}},

  year  = {2001}
}

@Article{   drummond2006,
  author = {Drummond, Chris and Holte, Robert C.},


  journal = {Machine Learning},
  keywords = {Classifiers,Machine learning,Performance evaluation,ROC
    curves},

  number = {1},
  pages  = {95--130},
  publisher = {Springer},
  title  = {{Cost curves: An improved method for visualizing
    classifier performance}},
  volume = {65},
  year  = {2006}
}

@inproceedings{brinker2020,
  title={A reduction of label ranking to multiclass classification},
  author={Brinker, Klaus and H{\"u}llermeier, Eyke},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2019, W{\"u}rzburg, Germany, September 16--20, 2019, Proceedings, Part III},
  pages={204--219},
  year={2020},
  organization={Springer}
}

@article{begoli2019,
  title={The need for uncertainty quantification in machine-assisted medical decision making},
  author={Begoli, Edmon and Bhattacharya, Tanmoy and Kusnezov, Dimitri},
  journal={Nature Machine Intelligence},
  volume={1},
  number={1},
  pages={20--23},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{yang2019,
  title={Unremarkable AI: Fitting intelligent decision support into critical, clinical decision-making processes},
  author={Yang, Qian and Steinfeld, Aaron and Zimmerman, John},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--11},
  year={2019}
}

@article{nti2020,
  title={A systematic review of fundamental and technical analysis of stock market predictions},
  author={Nti, Isaac Kofi and Adekoya, Adebayo Felix and Weyori, Benjamin Asubam},
  journal={Artificial Intelligence Review},
  volume={53},
  number={4},
  pages={3007--3057},
  year={2020},
  publisher={Springer}
}

@article{qayyum2020,
  title={Securing connected \& autonomous vehicles: Challenges posed by adversarial machine learning and the way forward},
  author={Qayyum, Adnan and Usama, Muhammad and Qadir, Junaid and Al-Fuqaha, Ala},
  journal={IEEE Communications Surveys \& Tutorials},
  volume={22},
  number={2},
  pages={998--1026},
  year={2020},
  publisher={IEEE}
}

@article{mullins2018,
  title={Adaptive generation of challenging scenarios for testing and evaluation of autonomous vehicles},
  author={Mullins, Galen E and Stankiewicz, Paul G and Hawthorne, R Chad and Gupta, Satyandra K},
  journal={Journal of Systems and Software},
  volume={137},
  pages={197--215},
  year={2018},
  publisher={Elsevier}
}

@article{scott2012,
  title={Calibrated asymmetric surrogate losses},
  author={Scott, Clayton},
  year={2012}
}

@inproceedings{coenen2020,
  title={Probability of default estimation, with a reject option},
  author={Coenen, Lize and Abdullah, Ahmed KA and Guns, Tias},
  booktitle={2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)},
  pages={439--448},
  year={2020},
  organization={IEEE}
}

@article{dubois2001,
  title={Possibility theory, probability theory and multiple-valued logics: A clarification},
  author={Dubois, Didier and Prade, Henri},
  journal={Annals of mathematics and Artificial Intelligence},
  volume={32},
  pages={35--66},
  year={2001},
  publisher={Springer}
}

@book{levi1980,
  title={The enterprise of knowledge: An essay on knowledge, credal probability, and chance},
  author={Levi, Isaac},
  year={1980},
  publisher={MIT press}
}

@book{vovk2005,
  title={Algorithmic learning in a random world},
  author={Vovk, Vladimir and Gammerman, Alexander and Shafer, Glenn},
  volume={29},
  year={2005},
  publisher={Springer}
}

@article{Alotaibi2021,
   author = {Reem Alotaibi and Peter Flach},
   doi = {10.1016/J.NEUCOM.2020.12.004},
   issn = {0925-2312},
   journal = {Neurocomputing},
   keywords = {Context,Cost-sensitive learning,Global threshold,Misclassification costs,Multi-label classification,Threshold choice methods},
   month = {5},
   pages = {232-247},
   publisher = {Elsevier},
   title = {Multi-label thresholding for cost-sensitive classification},
   volume = {436},
   year = {2021},
}


@inproceedings{charoenphakdee2021,
   author = {Nontawat Charoenphakdee and Zhenghang Cui and Yivan Zhang and Masashi Sugiyama},
   editor = {Marina Meila and Tong Zhang},
   journal = {Proceedings of the 38th International Conference on Machine Learning},
   month = {10},
   note = {- summary: The authors propose a very simple method to perform multi-class classification with reject option without the need of estimating accurate posterior probabilities. The reason being that the estimation of probabilities is more difficult, and not necessary in the context with fixed costs. The basic idea is to train K one-vs-rest classifiers with a zero-one-c loss (zero for correct classification, one for incorrect classification and c for abstention), then abstain if none of the models predict their class (uncertainty), or if more than one does (because of ambiguity), and predict the winning class otherwise. Their method only requires classification-calibrated losses to train and the results look very good for their method with sigmoid loss even with noisy data. One of the compared methods confidence-based (to estimate accurate posterior probabilities) is softmax with cross-entropy loss and Temperature scaling.- Proposes a new method to perform classification with a reject option by connecting hte cost-sensitive classification with classification with reject option.- Based on an ensemble of cost sensitive classifiers- (1) Do not require estimating posterior probabilities- (2) flexible losses even if non-convex- (3) easy ensemble with different losses- (4) binary or multiclass- (5) theory to support for any classification-calibrated loss- Cost-based framework(Chow, 1970; Barlett and Wegkamp, 2008; Yuan and Wegkamp, 2010; Cortes et al., 2016; Frank and Prusa, 2019; Ni et al., 2019) is commonly ussed for this setting- (A) confidence-based approaches (Bartlett and Wegkamp, 2008; Crandvalet et al. 2009; Herbei and Wegkamp, 2006; Yuan and Wegkamp, 2010; Ramaswamy et al., 2018; Ni et al., 2019): train posterior probability estimators and uses the confidence values to make the decision, which usually require proper losses, and may have difficulties to properly estimate the probabilities.- Some exceptions that do not require posterior probability estimations only for binary problems exist- (B) classifier-rejector (Cortes et al 2016): train a classifier and a rejector separately. It is theoreticall justified for binary case with hinge-loss. Does not seem applicable to the multiclass case with theoretical justification and empirical evidence (Ni et al 2019).- The main point is that the Bayes optimal solution only requires knowing which class has the maximum posterior probability, and if the posterior probability of that class is higher than 1 minus the cost c. (I need to understand this).- MPN: One think to bear in mind is that once this model is learned, I do not think it can be adjusted to new operating conditions. Need to check this.- They assume the rejection cost c is between 0 and 0.5- The authors use the zero-one-c loss (Ni et al., 2019) which is a zero-one loss with cost c when rejection.- Information for the case in which c > 0.5 can be found in Ramaswamy et al. (2018)- Chow's rule requires the posterior probabilities, if the confidence (maximum posterior among classes) is smaller than 1 - c then the model rejects. Otherwise the class with maximum posterior is chosen- Cost-sensitive binary does not assume equal costs. The authors propose alpha for one and 1 - alpha for the other. Scott (2012) defines the optimal cost-sensitive classifier predicting positive if its probability is higher than alpha, and negative otherwise.- The author explains that in Chow's rule, once the c is known, we do not need the posterior probabilities, but to know that this is below or above the threshold c. Which simplifies the overall task to classification rather than probability estimation (as suggested by Vapnik, 1998). - The multiclass case is also be done with Chow's rule and K binary cost-sensitive classifiers, when all of them reject, then reject, if not, select the class with maximum prediction.- A binary margin surrogate loss is proposed in Definition 5.- The final classification rule rejects if all binary predictions are negative, or si more than one is positive (ambiguity). Otherwise the only positive class is predicted.- Compared methods: (SCE) the confidence-based method with Softmax cross-entropy, (DEFER) the classifier-reject method proposed in Mozannar and Sontag (2020), (ANGLE) the beng hinge loss by Zhang et al. (2018), (CS-hinge) the authors method with hinge loss and (CS-sigmoid) with sigmoid loss.- Results for binary problems with clean and noisy datasets, as well as positive-unlabeled dataset shows generally the smallest zero-one-c risk for the proposed method with sigmoid loss (CS-sigmoid).- Their method with hinge loss got small risk on clean dataset and positive-ulabelled, but not in noisy settings.- The risk on the compared methods had mixed results.- Results on the multiclass setting show their method CS-sigmoid performing generally well (and the best in multiple ocasions), CS-hinge in a noisy setting performs bad, and sigmoid with cross entropy and temperature scaling (SCE) performed performed very well ocasionally.},
   pages = {1507-1517},
   publisher = {PMLR},
   title = {Classification with Rejection Based on Cost-sensitive Classification},
   volume = {139},
   url = {https://proceedings.mlr.press/v139/charoenphakdee21a.html http://arxiv.org/abs/2010.11748},
   year = {2021},
}


@inproceedings{deirdre2008,
   abstract = {For two-class classification, it is common to classify by setting a threshold on class probability estimates, where the threshold is determined by ROC curve analysis. An analog for multi-class classification is learning a new class partitioning of the multiclass probability simplex to minimize empirical misclassification costs. We analyze the interplay between systematic errors in the class probability estimates and cost matrices for multiclass classification. We explore the effect on the class partitioning of five different transformations of the cost matrix. Experiments on benchmark datasets with naive Bayes and quadratic discriminant analysis show the effectiveness of learning a new partition matrix compared to previously proposed methods.},
   author = {Deirdre B O'Brien and Maya R Gupta and Robert M Gray},
   city = {New York, NY, USA},
   doi = {10.1145/1390156.1390246},
   isbn = {9781605582054},
   journal = {Proceedings of the 25th International Conference on Machine Learning},
   pages = {712–719},
   publisher = {Association for Computing Machinery},
   title = {Cost-Sensitive Multi-Class Classification from Probability Estimates},
   url = {https://doi.org/10.1145/1390156.1390246},
   year = {2008},
}


@inproceedings{mozannar2020b,
   author = {Hussein Mozannar and David Sontag},
   editor = {Hal Daumé III and Aarti Singh},
   isbn = {9781713821120},
   journal = {37th International Conference on Machine Learning, ICML 2020},
   pages = {7033-7044},
   publisher = {PMLR},
   title = {Consistent estimators for learning to defer to an expert},
   volume = {PartF16814},
   url = {https://proceedings.mlr.press/v119/mozannar20b.html},
   year = {2020},
}


@inproceedings{zadrozny2001,
   abstract = {Accurate, well-calibrated estimates of class membership probabilities are needed in many supervised learning applications, in particular when a cost-sensitive decision must be made about examples with example-dependent costs. This paper presents simple but successful meth- ods for obtaining calibrated probability estimates from decision tree and naive Bayesian classi- fiers. Using the large and challenging KDD’98 contest dataset as a testbed, we report the re- sults of a detailed experimental comparison of ten methods, according to four evaluation mea- sures. We conclude that binning succeeds in significantly improving naive Bayesian probabil- ity estimates, while for improving decision tree probability estimates, we recommend smoothing by that we call curtailment. ? -estimation and a new variant of pruning},
   author = {Bianca Zadrozny and Charles Elkan},
   isbn = {1-55860-778-1},
   journal = {18th International Conference on Machine Learning (ICML'01)},
   pages = {609-616},
   title = {Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers},
   url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.3039&rep=rep1&type=pdf},
   year = {2001},
}

